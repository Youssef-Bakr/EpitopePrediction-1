{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import total_aaindex_parser\n",
    "import joblib\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import hyperparameter_tuning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here the Training data is Read in and converted to numbers    \n",
    "f = open('data/project_training.txt', \"r\")\n",
    "inputFile = open('data/test_input.txt', \"r\")\n",
    "outputFile = open('data/test_output.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['NFFHASLAY', 'YQKKNASVY', 'AAFLDDNAF', 'IQNKLSSTF', 'KLAEIFQPF', 'FAAAAARTL', 'MQQSGDEAF', 'KLRKKSSFY', 'GLGGDASAY', 'LQKVPHTRY', 'IQAGVDRFY', 'FQVNRFTGY', 'YFRNSGMTY', 'TVSPSAPTY', 'KTIQGGLGW', 'VMLDWGIEL', 'KLEGKIVQY', 'RMGAAVTPY', 'SQHNYRPGY', 'RGRAATMAL', 'QLFIKDYRY', 'FQLYSDLAH', 'FVFEATKLY', 'SQLEMCEKY', 'KVAAAGVSY', 'YVRGYLRGY', 'MQLQLNCAY', 'LLKPGGVQW', 'YLCEDTITY', 'VAGGTSSVY', 'WQFGPSTYY', 'ALEPGFKDY', 'IQGTLAKAY', 'TTFPVNGGY', 'ILSPHNVVT', 'KIFEYGFTF', 'GLVECNNHY', 'LLRDKDGVY', 'AFMATNKAY', 'AVLLHEESM', 'LMLADHPEY', 'LSDDAVVCY', 'FTERSDKSY', 'ITAGYNRYY', 'FVSVYFSDY', 'FLFMDRDAL', 'SSLPSYAAY', 'GQWDGWVWL', 'RLFFIDWEY', 'FSVQRNLPF', 'KLQLKGMSY', 'LQIPFAMQM', 'YLAGAGLAF', 'LMQWWSDYV', 'SQKHFDTWW', 'YQHLHTAPK', 'QQYHRFGLY', 'IVFATAARY', 'KMTPWSAYW', 'VVAVGGLAI', 'FVIGGMTGV', 'KQIANELNY', 'LAEQFSGEY', 'NQQVTNSKY', 'NLKLYGAEF', 'RQLESRLGY', 'AQAVMEMTY', 'KIISEIGQL', 'YTAVVPLVY', 'KQFDTYNLW', 'YMIKLAKEV', 'FVRQCFNPM', 'AENGWGFYF', 'KQINPPTVY', 'HTAEIQQFF', 'VQQESSFVM', 'PQVLGGLSF', 'AQIDNYNKF', 'RLAELIGPA', 'IQTHCEVGY', 'QLQANRRAY', 'IQVNKGVAY', 'KTIECSKEL', 'YLDDPDLKY', 'FQHERLGQF', 'QARQMVQAM', 'QQSEARRML', 'KQYNVTQAF', 'ISLEAGQRF', 'NIRQAGVQY', 'LQSLENVAY', 'ALMEITSRY', 'VMKRNFIDF', 'LLVAPAYSF', 'WQQWDRQSL', 'TVLDVGDAY', 'RLYYDSMSY', 'NQECWDSVF', 'ILGDTAWDF', 'AQLYAYAGF', 'VQGYERIMY', 'RLKTATYTF', 'SVKERGPAY', 'KSNEKNMDF', 'SQEAEFTGY', 'GMFGGCFAA', 'YQPEREKVY', 'IQRDQVTDY', 'GMHHLYREY', 'LQKGGVIVY', 'KSCLPACVY', 'AMIDRLHQT', 'RMYGISPWT', 'GVIMPNGSY', 'TQFESLKIY', 'IIMEEGNSI', 'QAFEAGIDF', 'WSILRQRCW', 'IMDEPTSSL', 'KTFSAHNLF', 'GMKRSFYVY', 'RVMAPRALL', 'RLKPVGSAY', 'AQNAISTTF', 'YTYPCIPEY', 'GQTGVIADY', 'VQLQEYDTY', 'EQNWDWNRY', 'VVQDPKNVY', 'GLVRALTAF', 'FHMDPSGTF', 'YQYPRDTHY', 'KVYWAGIEF', 'AQRPAKYSY', 'RMLPKLAEF', 'IMGIPYCNY', 'YMTLQAVTF', 'ELYPTVNTY', 'RTWHYCGSY', 'FLRGRAYGI', 'VMETENALF', 'TSNPKTPKY', 'WQFAIHYSF', 'TMLYNKMEF', 'TLASIGTAF', 'HERPVILSL', 'IMYDSGAKY', 'VIQLNRKSY', 'EQFPNATAF', 'KVMALPIPH', 'WSFLEDRVY', 'IAQLNRPAM', 'GQFGSGWTW', 'ILGPPGSVY', 'SQIETGTPF', 'LLWYRRGTF', 'ALSTGAGAY', 'VQLDWQGDY', 'KLIADSIDF', 'YIFRNTINM', 'LLFLPKAAY', 'GMMGGLWKY', 'ILGRYLPEF', 'AMAAAAAPY', 'ILLRKGHVF', 'VLFKTESGF', 'ITFHNQRDF', 'IMDASSFTL', 'TMKEGWIVY', 'GMKAFTAAV', 'AMFEEQNQW', 'MSNEGSYFF', 'KQFKQDAKY', 'ELNITSATY', 'NQLYLTVSF', 'STGPLHGCK', 'RLWNGRRCR', 'VKKLWGHLP', 'ATTHSWIPK', 'AIQIQMFEA', 'GSFKEYVFW', 'QATAQAAAY', 'WASRELERF', 'EKPKFLPDL', 'TFDVAPSRL', 'NSDYMMWVG', 'MTNRQFHQK', 'PSEVSPIAQ', 'RLRQLPKKK', 'KRFQPFQQF', 'GPGHKARVL', 'YRYTYRCHR', 'ARADGILRF', 'KTTFKPNTW', 'SVPEPAAGI', 'DFDGTPRLY', 'GRPNCFQIV', 'YFSGIMVRL', 'RRATAILRK', 'WMLGTGVYL', 'HIPEVCLKW', 'FIKDYRYTY', 'YRYGFVANF', 'IVDCLTEMY', 'FVDGVPFVV', 'IPRRIRQGL', 'YGDTEAICR', 'YFFVKWIGK', 'ETIEEPAVE', 'WAGIWGGKL', 'APYFATVRL', 'TYYPQVVLG', 'ILGETAWDF', 'RYFSVTRPL', 'EHAGVISVL', 'RRVSGCVSV', 'ETIFTVLAL', 'ASSWAPTQK', 'SHEGEGIPL', 'AHGWSTFYL', 'FLADYRGKT', 'LSDHQDLKW', 'DAYRRIHSL', 'GPRRAAWRI', 'DISPTNIPL', 'ATFSRPGSL', 'SKGETVNPL', 'DTDISQLHH', 'GYTPGQQFY', 'GVPPKVVSY', 'FPRGQGVPI', 'STDHIPILY', 'KNDAVYIGY', 'AEFWDVFLS', 'FKNSVFYSV', 'ILYVSCNPA', 'SSEQTFMYY', 'KTQEPPQVA', 'VVDKYFDCY', 'RLITVYVQA', 'RNEQGQTLW', 'AIKCVDIVK', 'SEYKAAGYL', 'RQIQVEGLK', 'GHLENNPAL', 'SRWGYQVKH', 'FSDARLAKL', 'RSFAERLDR', 'DLAAGVDVV', 'NGYRWQHQI', 'GVFELSDEK', 'RPPEVDGNR', 'ISYTYNDNW', 'SYLIRALTL', 'KVCRTLLAK', 'KTPWDRFCK', 'THADVPVVL', 'ALGYTTEEI', 'EADPTGHSY', 'RPPIFIRRL', 'YHFDPVHHL', 'DRYPANAIV', 'VMLLDIDYF', 'AITTPQMTL', 'ATLLSQVEV', 'HLGGFVHAC', 'RMGVKSQLL', 'RPWMLDKYF', 'KLMPICMDV', 'GRGQILLGK', 'QQLEADYTF', 'TPVWHVTSA', 'AVLQSGFRK', 'TAVPWNASW', 'KMSEYKGPV', 'MRVLHLDLK', 'DTKCKNNYF', 'YATVAGHEG', 'NPNSPSITY', 'RIKQIINMW', 'EIPGSPGSY', 'GTLSYDNLK', 'ASDRISGIL', 'RRRIGEIFK', 'VHTQKKDLY', 'ARYGIFLPF', 'ICDDVLSKY', 'AVAVHDFFK', 'RPRIRLSAP', 'HFQKDAKVL', 'DLPPAIAAE', 'SRKKGFLGL', 'GVKGFSFKY', 'ERSDKSYEH', 'RFEAYGWQV', 'RPKSNIVLL', 'MEIYIWDHD', 'KGPDKLQVY', 'GYSFSIPGY', 'WLWVSSSDM', 'RAPKVRLSL', 'HRDGKPRYL', 'FRNQVKIRR', 'NESGRLIDF', 'WGKEAVNHF', 'IAIPAHVRL', 'GEVGLDLTV', 'GRNSRFPDK', 'NRRFVNVVP', 'SSSLTSLLK', 'STHMENILK', 'QLQCHQIAI', 'LMTAISQGI', 'SADPLASLL', 'FPRSAERAG', 'ARLGKGYMF', 'EGFLKAAMF', 'CLWLLTLGL', 'IHESVIGQL', 'DPSMLRTTA', 'RRGPEQTQG', 'NMERKLNLS', 'GLENGLNYI', 'LPYPDPSRI', 'KSAQVPLPL', 'NSDDYTADE', 'WTDLYTSMS', 'RYQRMTGGY', 'GHYTHITAK', 'KCDICTDEY', 'KRMGVQMQR', 'CHKGWGVSV', 'KEKGPIFRD', 'ALWEIQQVV', 'PPSGKGGNY', 'GRNSFEVRV', 'IRNLVKRYK', 'LPEFERRTL', 'HLAGFIHAC', 'VRFPNITNL', 'ITDVQDMDP', 'VMTEGRHAV', 'KLQWLFAAL', 'MKWGMEMRR', 'RRKTNLYGF', 'DSDPMDGCE', 'RVFNNYMPY', 'RPVSPGKDI', 'ATISYRIKL', 'NANPDCKTI', 'PPQATAKYL', 'RTRFFCIPK', 'FLPGQYMNI', 'RVDFCGKGY', 'SSECQGEML', 'ATHKAPQPA', 'RYDYANLCQ', 'FAANPNSQV', 'IHKPRPPAT', 'QTHFPQFYW', 'MPASWVMRI', 'ATPQDLNTM', 'LVMAPRTVL', 'RVNKGTGVK', 'IASLTGWQW', 'ATNNVFRLK', 'CQTYKWETF', 'KLFIRQEEV', 'RLYEWQHVS', 'EIIELTRTL', 'YLDADREFL', 'GMDPRMCSL', 'GRSLEDDIR', 'YTPLNYSKF', 'GVNACQVGV', 'SQEDNHFSL', 'RPRGHREFC', 'RPYGKFRAM', 'ASDPSFPDI', 'MVDESMMMS', 'RVRIERGPR', 'DIIRAHPWF', 'GRRATAILR', 'ADFKLFFRW', 'APTGDLPRA', 'HHIPNGVVW', 'DWSGYSGSF', 'TLVPQEHYV', 'YTDDYPMYK', 'AAGLPAIFV', 'VVISKKDTY', 'VNGVKGIQF', 'AYSPFAFKK', 'SPAIFQSSM', 'AYLLQHLDL', 'VTTEVAFGL', 'WRDDSRGRW', 'TTRAWFDKK', 'ALIVAIWDK', 'DLSNSMRDF', 'FRKEFTKLE', 'DTFGVIDTM', 'HRIQEELFY', 'VMGGNAAEA', 'EVWGMRWPI', 'RRRQWASCM', 'IRHENRMVL', 'AEHDPWWAV', 'EFIYWDWLY', 'EHFYWGSVF', 'YIALGRARV', 'GYLNACGHF', 'EISGLRPGE', 'VGYVDDTQF', 'ERLQICQRK', 'AEIDRSFKP', 'KLGDQFGRK', 'IVLLCYGGW', 'PAHKSQLVW', 'IAFCNWAFV', 'TVANNPDDK', 'FPEHIFPAL', 'EEIDWIKTD', 'EFDNYRGTI', 'EEVWRDPYL', 'EEFTMVGRR', 'ALASFLFGF', 'VFLPNTHNL', 'RPLLARMPE', 'FGSGWTWVV', 'HIMPNSFRV', 'CADGTRHTY', 'GRDHVRVTL', 'ASLPTTIAK', 'LPLIVDTAA', 'GPATAQMAL', 'IPLTEEAEL', 'SSNVANYQK', 'ITGQIIFGF', 'EAFPYEITE', 'RFSFNCSMK', 'KLFAAETLK', 'KTFPPTEPK', 'PTKCGENLY', 'DFPIFNQRY', 'TSSDTYACW', 'NAHEGQLVI', 'SRALLLNKY', 'EPIVGAETF', 'AIKPITDQF', 'KLRQGNTLV', 'SEGDDDGSR', 'PSSKPDWFY', 'GKFFAQAFL', 'LLKDLMPFV', 'EKFFPSSSY', 'GLKRGGVLL', 'SRLKPSSFK', 'KSDGTGTIY', 'FPVTPQVPL', 'ELLSHVGQA', 'RQFVSNNGK', 'FTDGVCLFW', 'SPRTLNAWV', 'ATDFKFAMY', 'HVPTRGTAM', 'MRIPVERTL', 'AMVPLVMVI', 'FIFGKMGAG', 'AFASLQDML', 'FPREGVFVF', 'VTFQGKFKK', 'EVIPYTPAM', 'YQTDSGCWY', 'QPEWFRNVL', 'KYDDRIQSQ', 'PEIRRWIIF', 'MEFEPFQSL', 'YLGPTIRVW', 'NWDWGVFFK', 'YSDIPRLKK', 'YFSDVSAPV', 'VPAPAGPIV', 'LTLKPCHAL', 'STEIGLLVG', 'EVMPVSMAK', 'DYIYLPLLK', 'ILHCANFNV', 'PTDYMSSKL', 'RLLRMNNEN', 'YPKCDLVEL', 'FMHSAAPIT', 'TMPELAWAV', 'CTDDNALAY', 'KVIQPRVEK', 'AIPYFYKGK', 'ETVNFVPNY', 'GLYEAIEEC', 'IIANARIEV', 'PSEDEQQGH', 'QTPGVKIAP', 'YPAEITLTW', 'APIEHIASM', 'FHLRSRFAF', 'VPRVHNQPQ', 'TLAAAANSY', 'KTTIKFHPW', 'AANEIRISK', 'FFGWEGVGV', 'LTDDMIAAY', 'DQFSIPIRY', 'TVNVILRPK', 'RGINDRNFW', 'NMAPEKVDF', 'DPSGAYFAW', 'SLAIDAYPL', 'SALNHTKKW', 'MSSAMSMMH', 'YLHRDIFDI', 'DMYDQQLSV', 'AISAQVAAY', 'YQRPFGGQS', 'LFMSHVKSV', 'QTSTLYDFY', 'CYDLMSFLE', 'MGRDIKVQF', 'SMELPSFGV', 'ATQPVHWFL', 'RRFQHKDGH', 'YFDPANGKF', 'RHIAIQVCY', 'ISNQEPLKL', 'NMLREGLSP', 'MTMRRRLFK', 'RLEDVFAGK', 'ASHFISNSW', 'DPRDDLSGM', 'DYPDDFMDK', 'HEKGINPNY', 'EEQTDPKTL', 'WYETVKVNY', 'GSDGGLDDY', 'LYQPSSGCY', 'GLAGLQTDV', 'RKAGVNQAK', 'KMQRMLLEK', 'RRTPRVSWK', 'RRHWGGNVL', 'DYVPTNKWV', 'EIKFNDITF', 'FLHPKHWGT', 'VRDPKTSEI', 'NLGDKQDTF', 'ETFNTPAMY', 'TCDGNTFTY', 'ISNYICVAW', 'GKIKGKYSY', 'LPHQPLATY', 'ALYWALMES', 'VLPPLSADL', 'DLNKVIQFL', 'ELDEIGEDV', 'VTDGGEVGE', 'FADINGKLY', 'ITWETPMIW', 'EHGIVIRAF', 'LIFPAFFLC', 'LLTEVETYV', 'ADLRFASEF', 'NLEPGTFDL', 'RSEVELCIY', 'SYINRTGTF', 'TPYDINQML', 'EEMATKADY', 'SYPPPPASF', 'DLLENLQAY', 'RRVRDNMTK', 'APRQPGLMA', 'NPDIVIYQY', 'FMSLQSGDV', 'VLWAHGFEL', 'NILVAGNLI', 'RVRQLDESI', 'EVHIYYLEK', 'ALMRWRHPR', 'FLILCSVLL', 'STDTRHIPQ', 'AEGTGITHL', 'KIRLGFHWK', 'APRTVALTA', 'RRQWVLAFR', 'ISEPMFHQG', 'AYGSRFHEW', 'RPPGCTFPA', 'FRYMNSQGL', 'NPALRMKWM', 'LLQEKYGLI', 'CFMYSDFHF', 'RHYSASFKK', 'MSDIFHALV', 'RDALGRTAL', 'MCFHQHLMY', 'ASYRLCLYR', 'NPKTPKYKF', 'FYKRKAMAW', 'AQKLATKPV', 'KMVGTVQRV', 'YIFWIRTPR', 'TIPTNIPTL', 'YINMAWNLV', 'NPVPVGNIY', 'KLNHHKPPT', 'SVKEKDMTK', 'IVAWTRTAT', 'AYYWNQNGF', 'YHGEAMAIG', 'KRVDWSVEY', 'GVFKVWHPI', 'VVNYDNSTK', 'LYDYKENRF', 'SRDKTIIMW', 'PVDEYITTY', 'WPWNAREDV', 'YYLEKANKI', 'KAVRGDLNF', 'SRARIKTRL', 'IYYLEKANK', 'THYPTQNRF', 'VSPLAVTWW', 'AMHYIRHRA', 'EEIRRIWRQ', 'KPRSPVVEL', 'FAAFYFVFI', 'HFDDVANGF', 'FTFDNSKFV', 'SVMPAWQEK', 'LGYPFAWFL', 'IHDHGEQLF', 'RPMTYKAAL', 'ISVQPLWEW', 'AMAETGCDA', 'FRISGRGGK', 'HPDIVIYQY', 'ILKGKFQTA', 'ISSGETRSF', 'RPASAGAML', 'TSPDLSFSL', 'KTNDFAPAW', 'WMQELRAGA', 'LVYNHCEHG', 'TYQWIIRNW', 'KLLQICMWF', 'YAEISFMLW', 'LLPYPIAGC', 'PLWESATEV', 'DFIGKTIGF', 'RRQGNIYPK', 'GSDKQVVGQ', 'GSEDRDLLY', 'AEFPVGSTA', 'FVRSSNLKF', 'IADMGHLKY', 'IIMFDAEKL', 'LSEEIGLDL', 'LMPLARFWL', 'MKWMMAMKY', 'EPEPHILLF', 'TMKFKGTVD', 'ILWGYGFLQ', 'GLMWLSYFV', 'FPGEKRVSK', 'AFGLFWLVW', 'ETDVMTRGQ', 'QHTRRVSVL', 'KVGVYKMHK', 'KLPRMFLPK', 'APRALLLLL', 'SPRYIFTML', 'PLVQQEDDK', 'TVYPKTHYV', 'QYDDLHKKF', 'SYGNANVSF', 'EEDLPVTWR', 'FHNNWGATL', 'APILVVSGI', 'KFFPSSSYR', 'LMAEDLANV', 'HEGEGIPLY', 'AVDPAKAYK', 'SRIGAWASK', 'HSSVAGGLW', 'SRYWEPEFY', 'RLTGREGAV', 'SPADERAVA', 'IAGFIEGGW', 'WPISAILWF', 'PHYNNPWNT', 'IPSINVHHY', 'IYSAEFKNY', 'IVDYVTAYG', 'RTDPVIDNI', 'ERPAFGIQK', 'DVSPLMHLF', 'QPQQSPQFF', 'HPLSHFVNL', 'KLWAQCVQL', 'KTNFQNHKG', 'VPPTNSINK', 'GRLQSLQTY', 'DYAMHGTVF', 'RPRHQGVMV', 'IQCAGSEEK', 'GRYSVRYVR', 'RPQLGVGDV', 'RTGDIGCFK', 'VMCIQMKYV', 'RLFFKCIYR', 'TFMYVFSTF', 'AYQQGVKTL', 'VLTGNLQTL', 'TPKGPKVKY', 'RMFLAMITY', 'YQYIFLSFF', 'EIPQFMIGL', 'LIPDGDGEV', 'PPIPVGDIY'] ['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "def parseAaIndex():\n",
    "    source = \"data/aaindex1.txt\"\n",
    "    if not os.path.isfile(source):\n",
    "        source = \"../data/aaindex1.txt\"\n",
    "    input_file = open(source, \"r\")\n",
    "    lines = input_file.read().splitlines()\n",
    "    totalaaIndex = []\n",
    "    counter = 0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i][0] == \"I\":\n",
    "            bothLines = lines[i + 1] + lines[i + 2]\n",
    "            partielaaIndex = bothLines.split()\n",
    "            totalaaIndex.append(partielaaIndex)\n",
    "            counter += 1\n",
    "    input_file.close()\n",
    "    return totalaaIndex\n",
    "\n",
    "\n",
    "# Entfernt Eigenschaften in denen NA vorkommt und Floatet die Liste\n",
    "# Out: neue Liste der aaIndex-Eigenschaftens\n",
    "def getFeaturesforAAX():\n",
    "    a = parseAaIndex()\n",
    "    rmv = []\n",
    "    for feature in a:\n",
    "        if 'NA' in feature:\n",
    "            rmv.append(feature)\n",
    "    for feature in rmv:\n",
    "        a.remove(feature)\n",
    "    lst = []\n",
    "    for feature in a:\n",
    "        #b = feature.apply(float)\n",
    "        b = list(map(float, feature))\n",
    "        lst.append(b)\n",
    "    return lst\n",
    "\n",
    "\n",
    "def parseProjectTraining():\n",
    "    training_data = []\n",
    "    source = \"data/project_training.txt\"\n",
    "    if not os.path.isfile(source):\n",
    "        source = \"../data/project_training.txt\"\n",
    "    input_file = open(source, \"r\")\n",
    "    ligands = []\n",
    "    labels_str = []\n",
    "    next(input_file)\n",
    "    for line in input_file:\n",
    "        ligands.append(line.split(None, 1)[0])\n",
    "        labels_str.append(line[-2])\n",
    "    print(ligands, labels_str)\n",
    "    input_file.close()\n",
    "    labels = []\n",
    "    for i in range(len(labels_str)):\n",
    "        if(labels_str[i]!='\\t'):\n",
    "            temp = int(labels_str[i])\n",
    "            if temp:\n",
    "                labels.append(temp)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "    for x in range(0, len(ligands)):\n",
    "        if(line!='\\t'):\n",
    "            training_data.append([ligands[x], labels[x]])\n",
    "\n",
    "    return training_data, ligands, labels\n",
    "\n",
    "# Gibt Trainingsdaten aus\n",
    "# Out: Trainingsdaten\n",
    "def getTrainingData():\n",
    "    return trainingData\n",
    "\n",
    "\n",
    "# Gibt Liganden der Trainingsdaten aus\n",
    "# Out: Liganden des Trainingsdatensatzes\n",
    "def getLigands():\n",
    "    return ligands\n",
    "\n",
    "\n",
    "# Gibt Labels der Trainingsdaten aus\n",
    "# Out: Labels des Trainingsdatensatzes\n",
    "def getLabels():\n",
    "    return labels\n",
    "\n",
    "\n",
    "# Gibt Liste mit Features für die Trainingsdaten aus\n",
    "# Out: Features für Aminosäuren\n",
    "def getFeaturesForAS(x):\n",
    "    features_for_as = []\n",
    "    for feature in getFeaturesforAAX():\n",
    "        features_for_as.append(feature[x])\n",
    "    return features_for_as\n",
    "\n",
    "\n",
    "# Weist jeder Aminosäure seine Features zu\n",
    "# Out: Dictionary das jeder Aminosäure seine Eigenschaften zuweist\n",
    "def setAllFeatures():\n",
    "    aas = [\"A\", \"R\", \"N\", \"D\", \"C\", \"Q\", \"E\", \"G\", \"H\", \"I\", \"L\", \"K\", \"M\", \"F\", \"P\", \"S\", \"T\", \"W\", \"Y\", \"V\"]\n",
    "    feature_dic = {}\n",
    "    for x in range(0, len(aas)):\n",
    "        feature_dic.update({aas[x]: getFeaturesForAS(x)})\n",
    "    return feature_dic\n",
    "\n",
    "\n",
    "# Stellt Peptide als Feature-Vektor dar\n",
    "# In: Liganden und Features\n",
    "# Out: Liganden als Feature-Vektor\n",
    "def featureLigands(ligands, features):\n",
    "    a = setAllFeatures()\n",
    "    number_of_features = len(a[\"A\"])\n",
    "    ligands_featured = []\n",
    "    for x in range(0, len(ligands)):\n",
    "        peptide = []\n",
    "        for y in range(0, number_of_features):\n",
    "            for char in ligands[x]:\n",
    "                peptide.append(features[char][y])\n",
    "        ligands_featured.append(peptide)\n",
    "    return ligands_featured\n",
    "\n",
    "\n",
    "# Bereitet Trainingsdaten für SVM auf\n",
    "# Out: Skalierte und Selektierte Features und Labels der Trainingsdaten\n",
    "def prepareTrainingData():\n",
    "    # Einlesen der Trainingsdaten und casten in Numpy Array\n",
    "    labels = np.array(getLabels())\n",
    "    features = np.array(featureLigands(getLigands(), setAllFeatures()))\n",
    "    # Skalierung der Trainingsdaten mit MinMaxScaler\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    # Feature Selection mit 10 Percentil\n",
    "    selector = SelectPercentile(f_classif, percentile=10)\n",
    "    selector.fit(scaled_features, labels)\n",
    "    # Speichere Selektor um ihn bei INPUT später auch zu verwenden\n",
    "    joblib.dump(selector, './selector/selector.pkl')\n",
    "    selected_features = selector.transform(scaled_features)\n",
    "    return selected_features, labels\n",
    "\n",
    "# Lädt Trainingsdaten von training_data.txt\n",
    "trainingData, ligands, labels = parseProjectTraining()\n",
    "features, labels = prepareTrainingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(classifier, x_train, y_train, random_state):\n",
    "    # Choose classifier\n",
    "    if classifier == \"RF\":\n",
    "        clf = RandomForestClassifier(random_state=random_state)\n",
    "    elif classifier == \"SVM\":\n",
    "        clf = svm.SVC(random_state=random_state, probability=True, cache_size = 5000)\n",
    "    elif classifier == \"KNN_3\":\n",
    "        clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    elif classifier == \"KNN_5\":\n",
    "        clf = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif classifier == \"MLP\":\n",
    "        clf = MLPClassifier(random_state=random_state, max_iter=100000)\n",
    "    elif classifier == \"dummy\":\n",
    "        clf = DummyClassifier(random_state=random_state)\n",
    "    else:\n",
    "        clf = RandomForestClassifier(random_state=random_state)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    return clf\n",
    "\n",
    "def multilayer_perceptrom(x_train, y_train, rand_state):\n",
    "    clf = MLPClassifier(solver='sgd', activation='tanh', alpha=0.4, hidden_layer_sizes=(82, 31), learning_rate='constant', random_state=rand_state, max_iter=10000)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k fold validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
    "clf = multilayer_perceptrom(X_train, y_train, rand_state=2)\n",
    "#clf = multilayer_perceptrom(X_train, y_train, 3)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy k fold: \",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "df_conf_norm = df_confusion / df_confusion.sum(axis=0)\n",
    "\n",
    "sn.heatmap(df_confusion, cmap=\"YlOrRd\", annot=False)\n",
    "plt.show()\n",
    "sn.heatmap(df_conf_norm, cmap=\"YlOrRd\", annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.659 (+/-0.467) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.379 (+/-0.003) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.857 (+/-0.031) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.659 (+/-0.467) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.856 (+/-0.049) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.860 (+/-0.028) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.825 (+/-0.111) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.851 (+/-0.054) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.836 (+/-0.092) for {'C': 1, 'kernel': 'linear'}\n",
      "0.825 (+/-0.139) for {'C': 10, 'kernel': 'linear'}\n",
      "0.815 (+/-0.130) for {'C': 100, 'kernel': 'linear'}\n",
      "0.809 (+/-0.138) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        55\n",
      "           1       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.89        72\n",
      "   macro avg       0.86      0.83      0.84        72\n",
      "weighted avg       0.89      0.89      0.89        72\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.535 (+/-0.086) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.814 (+/-0.099) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.535 (+/-0.086) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.834 (+/-0.092) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.820 (+/-0.095) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.816 (+/-0.113) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.830 (+/-0.083) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.815 (+/-0.090) for {'C': 1, 'kernel': 'linear'}\n",
      "0.813 (+/-0.123) for {'C': 10, 'kernel': 'linear'}\n",
      "0.797 (+/-0.096) for {'C': 100, 'kernel': 'linear'}\n",
      "0.803 (+/-0.118) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        55\n",
      "           1       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.92        72\n",
      "   macro avg       0.88      0.88      0.88        72\n",
      "weighted avg       0.92      0.92      0.92        72\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "def hyperparams_svc():\n",
    "    # parameters to optimize\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "    classifier = SVC()\n",
    "    return classifier, tuned_parameters\n",
    "    \n",
    "def hyperparams(classifier, tuned_parameters, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    scores = ['precision', 'recall']\n",
    "    #scores = ['recall']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(\n",
    "            classifier, tuned_parameters, scoring='%s_macro' % score\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train, test in skf.split(features, labels):\n",
    "        X_train, X_test = features[train], features[test]\n",
    "        y_train, y_test = labels[train], labels[test]\n",
    "                                                                   \n",
    "classifier, tuned_parameters = hyperparams_svc()\n",
    "hyperparams(classifier, tuned_parameters, X_train, y_train, X_test, y_test)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotROC(pred_labels, test_labels):\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(test_labels, pred_labels)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([-0.1, 1.2])\n",
    "    plt.ylim([-0.1, 1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    print(\"ROC-Curve plotted\")\n",
    "    plt.show()\n",
    "plotROC(y_test, y_pred)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}